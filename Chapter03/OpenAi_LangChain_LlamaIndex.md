## 📝 Chapter 3: LLM 기반 애플리케이션 개발 프레임워크

### 1. LLM 애플리케이션 개발의 사분면

LLM을 활용하는 방법은 요구되는 LLM의 능력과 전달되는 정보의 복잡도에 따라 네 가지 영역으로 구분됩니다.

```
(전달되는 LLM의 정보)
   ^
   | [복잡]
   |   +-----------------------------+-----------------------------+
   |   |            RAG              |          에이전트           |
   |   |       (검색증강생성)        |                             |
   |   +-----------------------------+-----------------------------+
   |   |          프롬프트           |        LLM 파인튜닝         |
   |   |         엔지니어링          |                             |
   |   +-----------------------------+-----------------------------+
   | [간단]
   +--------------------------------------------------------------->
     [약함]              (LLM의 능력에 대한 요구)              [강함]

                <그림 3.6 LLM 기반 인공지능 애플리케이션 개발>
```

* **프롬프트 엔지니어링**: 가장 간단한 형태의 명령 최적화.
* **RAG (검색 증강 생성)**: 외부 데이터를 실시간으로 참조하여 답변의 정확성을 높임.
* **LLM 파인튜닝**: 특정 도메인 지식을 모델 자체에 학습시켜 언어 모델의 기저 능력을 강화.
* **에이전트**: LLM이 스스로 판단하여 도구를 사용하고 복잡한 목표를 달성하는 최상위 단계.

---

### 2. OpenAI API: 개발의 시작점

OpenAI API를 사용할 때 가장 중요한 파라미터 중 하나는 Temperature(온도)입니다.

* **Temperature**: 모델 출력의 무작위성을 제어합니다.
* **Low (0.0 ~ 0.3)**: 일관되고 논리적이며 예측 가능한 답변 (보고서, 코드 생성 등).
* **High (0.7 ~ 1.0)**: 창의적이고 다양한 변주가 있는 답변 (작문, 아이디어 브레인스토밍).



---

### 3. LangChain: 범용 LLM 오케스트레이션

LangChain은 LLM과 외부 데이터, 도구를 연결하여 복잡한 체인(Chain)을 구성하는 오픈소스 프레임워크입니다.

#### **A. 3대 장점**

1. **유연성**: 특정 모델에 종속되지 않고 다양한 LLM(GPT, Claude, Llama 등)을 교체하며 테스트 가능.
2. **캡슐화**: 프롬프트 템플릿, 메모리 관리 등 반복적인 기술적 세부사항을 컴포넌트화하여 제공.
3. **확장성**: 수많은 타사 서비스(Google Search, DB, Slack 등)와 이미 연결된 인터페이스 보유.

#### **B. 6대 핵심 모듈**

| 모듈 | 설명 |
| --- | --- |
| **Model I/O** | 모델 입력(프롬프트)과 출력(파싱)을 관리하는 인터페이스 |
| **Retrieval** | 외부 데이터(Vector DB 등)와 상호작용하여 관련 정보 검색 |
| **Chains** | 여러 구성 요소를 연결하여 하나의 실행 단위로 구축 |
| **Agents** | LLM이 판단하여 어떤 도구를 어떤 순서로 쓸지 결정 |
| **Memory** | 대화의 맥락이나 상태를 저장하여 연속성 유지 |
| **Callbacks** | 실행 중간 단계의 로그를 기록, 디버깅 및 모니터링 수행 |

---

### 4. LlamaIndex: 데이터 중심의 RAG 최적화

LlamaIndex는 특히 **검색 증강 생성(RAG)** 시스템 구축에 특화되어 있으며, 기업의 방대한 데이터를 효율적으로 연결하는 데 중점을 둡니다.

#### **A. RAG의 필요성 (파인튜닝 대비 장점)**

* **비용 효율성**: 매번 재학습할 필요 없이 데이터 색인만 갱신.
* **최신성**: 실시간 데이터를 즉시 검색하여 답변에 반영.
* **투명성**: 답변의 근거가 되는 출처 문서를 명확히 제시 가능.

#### **B. 핵심 도구 구성**

* **데이터 연결자 (Data Connectors)**: PDF, Notion, SQL 등 다양한 출처에서 데이터 수집.
* **데이터 색인 (Data Indexing)**: 데이터를 벡터(Vector) 형태로 변환하여 구조화.
* **엔진 (Engines)**: 자연어 질문에 대해 데이터를 검색하고 답변을 생성하는 통로.
* **통합 (Integration)**: LangChain 등 다른 생태계와의 매끄러운 연동 지원.

---

### 5. RAG 기반 작업 프로세스 (6단계)

RAG 시스템은 아래와 같은 순환 구조를 통해 사용자에게 최적의 답변을 제공합니다.

1. **사용자 요청**: 질문 또는 명령 입력.
2. **쿼리 변환**: 질문을 검색에 적합한 형태로 변환.
3. **정보 검색**: 색인된 데이터에서 관련성 높은 문서 조각(Chunks) 추출.
4. **컨텍스트 전달**: 검색된 정보를 프롬프트와 함께 LLM에 전달.
5. **응답 생성**: LLM이 제공된 정보를 바탕으로 답변 작성.
6. **최종 응답**: 사용자에게 검증된 정보 전달.

---

## 💭 회고

이번 학습을 통해 LangChain이 '연결과 흐름'**에 강점이 있다면, LlamaIndex는 '데이터의 구조화와 검색'에 강력한 전문성을 가지고 있음을 명확히 이해했습니다.

단순히 LLM을 사용하는 것을 넘어, **Temperature** 설정을 통한 섬세한 제어부터 **RAG**를 통한 데이터 보안 및 최신성 확보까지, 목적에 맞는 도구 선택의 기준이 세워졌습니다. 특히 파인튜닝의 한계를 RAG가 어떻게 보완하는지 파악한 것은 실무적인 아키텍처 설계에서 매우 중요한 이정표가 될 것입니다.

"도구는 목적을 앞서지 않는다"는 원칙 아래, 복잡한 비즈니스 로직은 LangChain으로, 정교한 데이터 검색 시스템은 LlamaIndex로 구축하는 하이브리드 전략을 고민해 볼 시점입니다.

---