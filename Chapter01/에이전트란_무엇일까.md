## 📝 Chapter 1: LLM 에이전트의 이해와 진화

### 1. 인공지능에서 '에이전트'로의 패러다임 전환

기존의 인공지능이 정해진 규칙 안에서 움직이는 '수동적인 도구'였다면, 에이전트는 환경을 이해하고 스스로 판단하는 '자율적 주체'입니다.

* **전통적 AI**: 한정된 환경, 미리 설정된 작업만 수행 (유연성 및 자가 적응 능력 부족)


* **AI 에이전트**: 지능을 가진 객체로서 자율성을 가짐
* **감지(Perception)**: 환경에서 정보를 수집
* **결정(Decision)**: 수집된 정보를 바탕으로 계획 수립
* **행동(Action)**: 계획에 따라 환경에 영향을 주는 활동 수행



### 2. 에이전트의 4가지 핵심 특성

에이전트라고 불리기 위해서는 다음의 네 가지 요소를 갖추어야 합니다.

1. **자율성(Autonomy)**: 외부의 간섭 없이 스스로 결정하고 실행
2. **적응성(Adaptability)**: 학습을 통해 환경에 맞춰 능력을 향상
3. **상호작용성(Interactivity)**: 인간 또는 다른 시스템과 소통하며 서비스 제공
4. **기능성(Functionality)**: 특정 영역에서 구체적인 태스크를 완수

### 3. 기술적 구성 요소 (Architecture)

에이전트가 동작하는 내부 메커니즘은 크게 네 부분으로 나뉩니다.

* **감지기(Sensor)**: 실시간 데이터, DB, 인터넷 등에서 정보 수집
* **지식 저장소(Knowledge Base)**: 목표, 이전 경험, 상태 정보를 관리
* **의사 결정 엔진(Decision Engine)**: 감지된 정보와 지식을 결합해 논리적 판단 (LLM의 핵심 역할)
* **실행기(Executor)**: 메시지 전송, API 호출 등 실제 행동 취득

---

### 4. LLM이 가져온 에이전트의 혁명

에이전트는 LLM 이전과 이후로 나뉩니다. 과거의 에이전트가 특정 규칙(Symbolic)이나 보상(RL)에 의존했다면, LLM 기반 에이전트는 '언어 기반의 사고 능력'을 가집니다.

| 구분 | 주요 특징 |
| --- | --- |
| **LLM 이전** | 기호 논리, 반응형 에이전트, 강화학습 기반 (특정 도메인에 국한) |
| **LLM 이후** | **동적 의사 결정자**로 진화. 방대한 세계 지식 사전 학습 |
| **핵심 기법** | CoT(사고의 연쇄), ReAct(추론+행동), 문제 분해(Decomposition) |

> **Key Takeaway**: 사전 학습된 LLM은 **Zero-shot/Few-shot** 능력이 뛰어나기 때문에, 별도의 매개변수 업데이트 없이도 새로운 작업에 즉각 투입될 수 있는 강력한 일반화 성능을 보입니다.

---

## 💭 회고

이번 장을 통해 AI를 바라보는 패러다임이 '정해진 답을 내놓는 도구'에서 '스스로 판단하고 행동하는 주체'로 완전히 변화했음을 느꼈습니다.

특히 인상 깊었던 점은 LLM이 단순히 '문장을 생성하는 모델'이 아니라, 감지와 실행 사이를 잇는 '의사 결정 엔진' 역할을 한다는 점입니다. 이전의 에이전트들이 특정 환경에 종속되어 확장이 어려웠던 반면, LLM은 방대한 세계 지식과 CoT(사고의 연쇄) 같은 논리 체계를 통해 Zero-shot으로 새로운 작업에 적응할 수 있다는 점이 엔지니어로서 매우 강력한 무기로 다가왔습니다.

결국 에이전트 개발의 핵심은 "얼마나 좋은 LLM을 쓰느냐"를 넘어, "LLM이 주변 환경을 어떻게 감지하게 하고, 어떤 실행 도구를 쥐여줄 것인가"라는 시스템 설계의 문제라는 것을 깨달았습니다.